---
title: "Automated ITD prioritiser"
output: html_document
date: "2023-03-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r }
library(tidyr)
library(dplyr)

# set the path to the directory containing the files
path <- "/home/briana/shared/ProcessedVEPInsertions/Test"

# list all the text files in the directory
files <- list.files(path, pattern = "\\.txt$", full.names = TRUE)


# read and process each file, and combine the data into one table
combined_df <- lapply(files, function(file) {
  # read the file
  vcf <- read.table(file, header = FALSE, comment.char = "#", sep = "\t")
  
  # split the 8th column into multiple columns
  new_df <- separate(vcf, 8, into = paste0("col", 1:40), sep = "\\|")
  
  # add the file name as another column
  new_df$file_name <- file
  
  # return the processed data
  new_df
}) %>% 
  bind_rows() %>%
  mutate(file_name = basename(file_name)) %>% 
  select(file_name, everything())





```



```{r create split DB}

library(dplyr)


df_split <- separate(combined_df, 'col1', into = c("EVENT", "PAIRID", "SVLEN","SVTYPE","CSQ"), sep = ";")
df_split$SVLEN <- gsub("SVLEN=", "", df_split$SVLEN)
df_split$SVLEN <- as.integer(df_split$SVLEN)
df_split <-df_split %>% rename(ExistingVariant = 'col18')
df_split <- subset(df_split, V1 != "chrM") #Remove mitochondrial information
df_split <- df_split %>% 
  mutate(id = row_number())






```

```{r} 
#This block determines the Levenshtein score for the data frame for each variant, when comparing the variant to the left and right sequence at the insertion point. 

# Determine the length of the alt sequence
df_split$alt_length <- nchar(df_split$V5)

# Skip variants where the alt sequence is too short (not interested in insertions less than 3 bases)
alt_length_threshold <- 3
df_split<- subset(df_split, df_split$alt_length >= alt_length_threshold)

# Convert the chromosome name to the RefSeq accession number
chrom_to_accession <- list(chr1 = "NC_000001.11", chr2 = "NC_000002.12", chr3 = "NC_000003.12", chr4 = "NC_000004.12", chr5 = "NC_000005.10", chr6= "NC_000006.12", chr7 = "NC_000007.14", chr8= "NC_000008.11", chr9= "NC_000009.12", chr10 = "NC_000010.11", chr11 = "NC_000011.10", chr12 = "NC_000012.12", chr13 = "NC_000013.11", chr14 = "NC_000014.9", chr15 = "NC_000015.10", chr16 = "NC_000016.10", chr17 = "NC_000017.11", chr18 = "NC_000018.10", chr19 = "NC_000019.10", chr20 = "NC_000020.11", chr21 = "NC_000021.9", chr22 = "NC_000022.11", chrX = "NC_000023.11",chrY = "NC_000024.10") 


df_split <- df_split[df_split$V1 %in% names(chrom_to_accession), ]
df_split$accession <- chrom_to_accession[match(df_split$V1, names(chrom_to_accession))]

# Define the start and end positions for the reference sequence
df_split$start <- as.integer(df_split$V2) - 1
df_split$end <- df_split$start + df_split$alt_length

# Use system() to retrieve the reference sequences
ref_fasta_path <- "/home/briana/shared/AdjacentSequence/ncbi-genomes-2023-04-08/GCF_000001405.40_GRCh38.p14_genomic.fna"
df_split$ref_fasta_cmd_right <- paste0("samtools faidx ", ref_fasta_path, " ", df_split$accession, ":", df_split$start+1, "-", df_split$end)
df_split$ref_seq_right <- sapply(df_split$ref_fasta_cmd_right, function(cmd) system(cmd, intern = TRUE)[2])
df_split$ref_fasta_cmd_left <- paste0("samtools faidx ", ref_fasta_path, " ", df_split$accession, ":", df_split$start-df_split$alt_length, "-", df_split$start-1)
df_split$ref_seq_left <- sapply(df_split$ref_fasta_cmd_left, function(cmd) system(cmd, intern = TRUE)[2])

# Compare the alt and reference sequences using Levenshtein distance
library(stringdist)
df_split$lev_distance_right <- stringdist(df_split$ref_seq_right, df_split$V5, method = "lv", nthread = 4)
df_split$lev_distance_left <- stringdist(df_split$ref_seq_left, df_split$V5, method = "lv", nthread = 4)


# Append the new information as a new column to the variant line
df_split$new_info_right <- ifelse(df_split$lev_distance_right != -1, paste0("Levenshtein=", df_split$lev_distance_right, "| Original sequence(right)=", df_split$ref_seq_right, ", Variant sequence=", df_split$V5), paste0("Levenshtein=", df_split$lev_distance_right, "|"))
df_split$new_info_left <- ifelse(df_split$lev_distance_left != -1, paste0("Levenshtein=", df_split$lev_distance_left, "| Original sequence(left)=", df_split$ref_seq_left, ", Variant sequence=", df_split$V5), paste0("Levenshtein=", df_split$lev_distance_left, "|"))




```

```{r}
#This block calculates a ratio of the score over the length of the variant to account for an increased number of of changes in longer variants, and adds this information to the data frame.

# Add scaled Levenshtein distances to df_split
df_split$lev_distance_right_scaled <- df_split$lev_distance_right / nchar(df_split$V5)
df_split$lev_distance_left_scaled <- df_split$lev_distance_left / nchar(df_split$V5)
```

```{r}
#Returns data frame with information from COSMIC census database 
library(RSQLite)
library(dplyr)

# Create a connection to your SQLite database
con <- dbConnect(RSQLite::SQLite(), "/home/briana/shared/a_census_db.db")

# Create a new dataframe called COSV_df that contains rows where ExistingVariant contains COSV and col3 contains "HIGH" or "MODERATE"
COSV_df <- df_split %>% filter(grepl("COSV", ExistingVariant) & col3 %in% c("HIGH", "MODERATE"))

# Define a function to extract the COSV ID from the ExistingVariant column
extract_COSV <- function(variant) {
  COSV_id <- gsub(".*(COSV\\d+).*", "\\1", variant)
  return(COSV_id)
}

# Apply the extract_COSV function to the ExistingVariant column of COSV_df using lapply
COSV_ids <- unlist(lapply(COSV_df$ExistingVariant, extract_COSV))

get_gene_info <- function(COSV_id, db_conn) {
  query <- paste0("SELECT `Gene name`,`Primary histology`, `Histology subtype 1`, `Histology subtype 2`,`Resistance mutation`, `Mutation somatic status`, GENOMIC_MUTATION_ID FROM a_census_table WHERE GENOMIC_MUTATION_ID = '", COSV_id, "'")
  gene_info <- dbGetQuery(db_conn, query)
  gene_info$`Histology subtype 2` <- as.character(gene_info$`Histology subtype 2`)
  # Convert other columns as needed
  return(gene_info)
}


# Apply the get_gene_info function to each COSV_id in the COSV_ids list using lapply, and combine the resulting data frames using bind_rows()
gene_info_census_df <- bind_rows(lapply(COSV_ids, get_gene_info, db_conn = con))

# Disconnect from the SQLite database
dbDisconnect(con)


```



```{r}
#This block searches through the COSV_df and connects it to information in the gene_info_census dataframe using nested lists. 


# Loop through each row in COSV_df
for (i in 1:nrow(COSV_df)) {
  # Get the values of file_name and ExistingVariant for this row
  file_name <- COSV_df[i, "file_name"]
  ExistingVariant <- unlist(strsplit(as.character(COSV_df[i, "ExistingVariant"]), ";"))
  
  # Separate out COSV IDs if there are multiple of them in the same cell
  ExistingVariant <- unlist(strsplit(ExistingVariant, "&"))
  
  # Remove any "rs" values that are not cosmic values
  ExistingVariant <- ExistingVariant[grepl("^COSV", ExistingVariant)]
  
  # Search for matching rows in gene_info_census_df based on each COSV value
  matching_rows <- list()
  for (j in 1:length(ExistingVariant)) {
    matching_rows[[j]] <- subset(gene_info_census_df, grepl(ExistingVariant[j], GENOMIC_MUTATION_ID))
  }
  
  # Combine the matching rows into a single dataframe
  if (length(matching_rows) > 0) {
    matching_df <- do.call(rbind, matching_rows)
  } else {
    matching_df <- data.frame()
  }
  
  # Create a list containing file_name, ExistingVariant, and matching_rows
  merged_list[[i]] <- list(file_name = file_name, ExistingVariant = ExistingVariant, matching_df = matching_df)
}

# Combine the lists in merged_list into a dataframe
merged_df <- data.frame(do.call(rbind, merged_list))




```

```{r}

library(dplyr)
library(tidyr)

# Get the unique genomic mutation IDs and associated histology subtype 1, primary histology, and gene symbol
unique_ids <- gene_info_census_df %>% 
  distinct(GENOMIC_MUTATION_ID, .keep_all = TRUE) %>% 
  select(GENOMIC_MUTATION_ID, `Histology subtype 1`, `Primary histology`, `Gene name`) %>%
  mutate(Genomic_Mutation_and_Histology = GENOMIC_MUTATION_ID)

# Get the counts of each histology subtype 1, primary histology, gene symbol and gene name combination
counts <- unique_ids %>% 
  count(`Histology subtype 1`, `Primary histology`, `Gene name`) %>%
  arrange(desc(n))

# Create a data frame to store the results
results_df <- data.frame(Row_Num = integer(),
                         Histology_subtype = character(),
                         Primary_histology = character(),
                         Gene_name = character(),
                         Genomic_Mutation = character(),
                         Count = integer(),
                         stringsAsFactors = FALSE,
                         row.names = NULL)

# Populate the data frame with the results
for (i in seq_len(nrow(counts))) {
  histology_subtype <- counts$`Histology subtype 1`[i]
  primary_histology <- counts$`Primary histology`[i]
  gene_name <- counts$`Gene name`[i]
  subset_df <- unique_ids %>%
    filter(`Histology subtype 1` == histology_subtype & `Primary histology` == primary_histology & `Gene name` == gene_name)
  genomic_mutations <- paste(subset_df$Genomic_Mutation_and_Histology, collapse = ", ")
  count <- counts$n[i]
  results_df <- rbind(results_df, data.frame(Row_Num = i,
                                             Histology_subtype = histology_subtype,
                                             Primary_histology = primary_histology,
                                             Gene_name = gene_name,
                                             COSV_Census_ID = genomic_mutations,
                                             Count = count,
                                             stringsAsFactors = FALSE))
}

# Replace Histology_subtype with row numbers
results_df$Row_Num <- seq_len(nrow(results_df))
results_df_gene_summary <- results_df[c("Row_Num", "Primary_histology",  "Histology_subtype", "Gene_name", "COSV_Census_ID" , "Count")]





```


```{r}
#Generate results_df_summary_split
library(tidyr)

# use separate_rows() to split the cells in "COSV_Census_ID" column
df_summary_split <- separate_rows(results_df_gene_summary, COSV_Census_ID, sep = ",")

# print the updated dataframe
print(df_summary_split)


```

```{r}
library(data.table)
library(stringr)

id_list_COSV_Census_ID <- unique(df_summary_split$COSV_Census_ID)

result_df <- data.frame(unique_cosv_census_id = character(),
                         file_name = character(),
                         stringsAsFactors = FALSE)

for (i in id_list_COSV_Census_ID) {
  
  # check if the i value is a split COSV value
  if (grepl("&", i)) {
    # split the COSV value into separate values
    i_split <- str_split(i, "&", simplify = TRUE)[, 1:2]
    # create a regular expression to match either of the split values
    i_regex <- paste0("^", i_split, "$", collapse = "|")
    cat("Regex for", i, ":", i_regex, "\n")
    # subset df_split using the regular expression
    df_temp <- df_split[str_detect(df_split$col18, i_regex), ]
  } else {
    # if the i value is a single COSV value, simply subset df_split
    df_temp <- df_split[df_split$col18 == i, ]
  }
  
  if (nrow(df_temp) > 0) {
    result_df <- rbind(result_df, data.frame(unique_cosv_census_id = i, 
                                             file_name = df_temp$file_name,
                                             stringsAsFactors = FALSE))
  }
}

```



```{r} 
# Loop over the id_list_COSV_Census_ID
# Create an empty data frame to store the matching rows

matching_rows_df <- data.frame()

my_list_trimmed <- lapply(id_list_COSV_Census_ID, trimws)

for (i in my_list_trimmed) {
  result <- grepl(i, df_split$ExistingVariant)
  matching_rows <- df_split[result, ]
  if (nrow(matching_rows) > 0) {
    matching_rows$i <- i
    matching_rows_df <- rbind(matching_rows_df, matching_rows)
  }
}


matching_Id_df <- subset(matching_rows_df, select = c(file_name, i, col4))

matching_Id_df <- matching_Id_df[order(matching_Id_df$file_name), ]


  




```


```{r}
#Extract contig ID for VAF matching from matching_Id_df - file name only - for COSVgenes - this also removes duplicates

matching_contigs_df <- subset(matching_rows_df, select = c(file_name, V3))
unique_file_names_df <- unique(matching_contigs_df["file_name"])
write.table(unique_file_names_df, file = "/home/briana/shared/filelistforCOSVgenes.txt", sep = "\t", row.names = FALSE, quote = FALSE)




```

```{r}
#Extract filename and contig ID

matching_contigs_df <- subset(matching_rows_df, select = c(file_name, V3))
write.table(matching_contigs_df, file = "/home/briana/shared/contigslistforCOSVgenes.txt", sep = "\t", row.names = FALSE, quote = FALSE)

```



```{r}
#Extract file name to get results files for no database values

matching_contigs_df_nodb<- subset(df_split_noDBENTRY, select = c(file_name, V3, col4))
write.table(df_split_noDBENTRY["file_name"], file = "/home/briana/shared/filenamesnodb.txt", sep = "\t", row.names = FALSE, quote = FALSE)

#This removes duplicates from the file so we are not copying across so many results files 
# Read in the text file
matching_contig_namesnodb <- read.table("/home/briana/shared/filenamesnodb.txt", header = TRUE, sep = "\t")

# Remove duplicates from the column
unique_values_nodb <- unique(matching_contig_namesnodb$file_name)

# Write the unique values to a new text file
write.table(unique_values_nodb, file = "/home/briana/shared/filenamesnodbnoduplicates.txt", sep = "\t", row.names = FALSE, quote = FALSE)



```

```{r}
#Create text file with file name, contig_id for no db entry
contigs_filename_nodb <- subset(df_split_noDBENTRY, select = c(file_name, V3))
write.table(contigs_filename_nodb, file = "/home/briana/shared/filenamescontignodb.txt", sep = "\t", row.names = FALSE, quote = FALSE)


```



```{r}
#Import VAF values for COSV variants

VAF_COSMIC_values <- read.table("/home/briana/shared/matchingVAFValuesforCOSV.txt", header = FALSE, sep = "\t")
names(VAF_COSMIC_values)[names(VAF_COSMIC_values) == "V6"] <- "VAF"
```


```{r}
#Remove extra genes from VAF_COSMIC_Values

matching_Id_df_genes_list <- matching_Id_df$col4

# Create new data frame to store matching rows
COSV_genes_only_df <- data.frame()

# Loop through column1 and check if each value is in the list
for (value in VAF_COSMIC_values$V2) {
  if (value %in% matching_Id_df_genes_list) {
    # If value is in the list, add the corresponding row to the new data frame
    COSV_genes_only_df <- rbind(COSV_genes_only_df, VAF_COSMIC_values[VAF_COSMIC_values$V2 == value, ])
  }
}

# Print the new data frame
COSV_genes_only_df

```


```{r}
#Generate VAF dataframe for top 20 genes by count MODERATE and HIGH impact, no associated database entry 


# Subset the data frame based on conditions
new_df <- df_split[df_split$ExistingVariant == "" & 
                   !(df_split$col3 %in% c("LOW", "MODIFIER")), ]

# Count the frequency of col4 values and find the top n values
top_vals <- names(sort(table(new_df$col4), decreasing = TRUE)[1:20])

# Subset the data frame to keep rows with top col4 values
new_df_top_20_noDB_genes <- new_df[new_df$col4 %in% top_vals, ]

# Print the new data frame
new_df_top_20_noDB_genes



```


```{r}
#Extract contig ID for VAF matching from new_df_top_20_noDB_genes

matching_contigs_df_no_COSV<- subset(new_df_top_20_noDB_genes, select = c(file_name, V3, col4))
matching_contigs_df_no_COSV_list<- matching_contigs_df_no_COSV[,2]
write(matching_contigs_df_no_COSV_list, file = "/home/briana/shared/contigslistfornoCOSVgenes.txt")


```


```{r}
#Import VAF values for  no COSV variants

VAF_noCOSMIC_values <- read.table("/home/briana/shared/matchingVAFValuesfornoCOSV.txt", header = FALSE, sep = "\t")
names(VAF_noCOSMIC_values)[names(VAF_noCOSMIC_values) == "V6"] <- "VAF"

```

```{r}
#Remove extra genes from VAF_noCOSMIC_Values (due to duplications in contig ID)

matching_ID_df_noCOSVgenes_list <- new_df_top_20_noDB_genes$col4

# Load dplyr package
library(dplyr)

# Filter the rows where V2 value is in matching_ID_df_noCOSVgenes_list
filtered_VAF_noCOSMIC_values <- VAF_noCOSMIC_values %>%
  filter(V2 %in% matching_ID_df_noCOSVgenes_list)


```

```{r}
#Import example result file from MINTIE to check column headings 

exampleresultfile<- read.csv("/home/briana/shared/TestFile/dupe_realn_results.tsv", header = TRUE, sep = "",  na.strings = "NA","")
exampleresultfile <- exampleresultfile[exampleresultfile$variant_type == "NE", ]

```

```{r}
#Import result file for insertions with COS data base entries 
library(dplyr)

result_lines_from_hpc_COSV <- read.csv("/home/briana/shared/VAFAnalysis/resultlinesforCOSV.txt", header = FALSE, sep = "", na.strings = "NA")
result_lines_from_hpc_COSV  <- result_lines_from_hpc_COSV [result_lines_from_hpc_COSV $V8 == "INS", ]
colnames(result_lines_from_hpc_COSV )[32] <- "case_reads"
colnames(result_lines_from_hpc_COSV )[33] <- "controls_total_reads"
colnames(result_lines_from_hpc_COSV )[9] <- "genes"
colnames(result_lines_from_hpc_COSV )[14] <- "VAF"

gene_counts_lines_COSV <- result_lines_from_hpc_COSV  %>%
  group_by(genes) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  top_n(20, count)


#Filter for variants with over 1000 case reads and over 500 control_total_reads

result_lines_from_hpc_COSV$controls_total_reads <- as.numeric(result_lines_from_hpc_COSV$controls_total_reads)

filtered_result_lines_COSV <- result_lines_from_hpc_COSV %>%
  filter(case_reads > 100, 
         !is.na(controls_total_reads),
         controls_total_reads > 25,
         VAF >= 0.1)


gene_counts_lines_from_hpc_filtered_COSV <- filtered_result_lines_COSV %>%
  group_by(genes) %>%
  summarise(count = n(), 
            avg_vaf = mean(VAF), 
            avg_case_reads = mean(case_reads),
            avg_controls_total_reads = mean(controls_total_reads)) %>%
  arrange(desc(count)) %>%
  top_n(20, count)



```


```{r}
#Import result file for insertions with no data base entries 
library(dplyr)

result_lines_from_hpc_noDB <- read.csv("/home/briana/shared/VAFAnalysis/resultlinesnoDB.txt", header = FALSE, sep = "", na.strings = "NA")
result_lines_from_hpc_noDB  <- result_lines_from_hpc_noDB  [result_lines_from_hpc_noDB $V8 == "INS", ]
colnames(result_lines_from_hpc_noDB )[32] <- "case_reads"
colnames(result_lines_from_hpc_noDB )[33] <- "controls_total_reads"
colnames(result_lines_from_hpc_noDB )[9] <- "genes"
colnames(result_lines_from_hpc_noDB  )[14] <- "VAF"

gene_counts_lines_noDB <- result_lines_from_hpc_COSV  %>%
  group_by(genes) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  top_n(20, count)


#Filter for variants with over 1000 case reads and over 500 control_total_reads

result_lines_from_hpc_noDB $controls_total_reads <- as.numeric(result_lines_from_hpc_noDB $controls_total_reads)

filtered_result_lines_noDB <- result_lines_from_hpc_noDB  %>%
  filter(case_reads > 1000, 
         !is.na(controls_total_reads),
         controls_total_reads > 500,
         VAF >= 0.1)


gene_counts_lines_from_hpc_filtered_noDB <- filtered_result_lines_noDB%>%
  group_by(genes) %>%
  summarise(count = n(), 
            avg_vaf = mean(VAF), 
            avg_case_reads = mean(case_reads),
            avg_controls_total_reads = mean(controls_total_reads)) %>%
  arrange(desc(count)) %>%
  top_n(20, count)

#Create new df based on results for Levenshtein filtering 
NoDB_filtered_for_levenscore <- inner_join(df_split, filtered_result_lines_noDB, 
                                           by = c("file_name" = "V1", "V3" = "V11"))


```


```{r}
#Import result file for insertions with COS data base entries 
library(dplyr)

result_lines_from_hpc <- read.csv("/home/briana/shared/resultlinesfromhpc.txt", header = FALSE, sep = "", na.strings = "NA")
result_lines_from_hpc <- result_lines_from_hpc[result_lines_from_hpc$V8 == "INS", ]
colnames(result_lines_from_hpc)[32] <- "case_reads"
colnames(result_lines_from_hpc)[33] <- "controls_total_reads"
colnames(result_lines_from_hpc)[9] <- "genes"
colnames(result_lines_from_hpc)[14] <- "VAF"


gene_counts_lines_from_hpc <- result_lines_from_hpc %>%
  group_by(genes) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  top_n(20, count)


#Filter for variants with over 1000 case reads and over 500 control_total_reads

result_lines_from_hpc$controls_total_reads <- as.numeric(result_lines_from_hpc$controls_total_reads)

filtered_result_lines <- result_lines_from_hpc %>%
  filter(case_reads > 100, 
         !is.na(controls_total_reads),
         controls_total_reads > 25)

gene_counts_lines_from_hpc_filtered <- filtered_result_lines %>%
  group_by(genes) %>%
  summarise(count = n(), 
            avg_vaf = mean(VAF), 
            avg_case_reads = mean(case_reads),
            avg_controls_total_reads = mean(controls_total_reads)) %>%
  arrange(desc(count)) %>%
  top_n(20, count)


#Create new df based on results for Levenshtein filtering 

COSV_filtered_for_levenscore <- inner_join(df_split, filtered_result_lines_COSV, 
                                           by = c("file_name" = "V1", "V3" = "V11"))




```


```{r}
#Levenshtein score for insertions that meet VAF and control count values - no DB entries
#This block determines the Levenshtein score for the data frame for each variant, when comparing the variant to the left and right sequence at the insertion point. 

# Determine the length of the alt sequence
NoDB_filtered_for_levenscore$alt_length <- nchar(NoDB_filtered_for_levenscore $V5.x)

# Skip variants where the alt sequence is too short (not interested in insertions less than 3 bases)
alt_length_threshold <- 3
NoDB_filtered_for_levenscore <- subset(NoDB_filtered_for_levenscore , NoDB_filtered_for_levenscore  $alt_length >= alt_length_threshold)

# Convert the chromosome name to the RefSeq accession number
chrom_to_accession <- list(chr1 = "NC_000001.11", chr2 = "NC_000002.12", chr3 = "NC_000003.12", chr4 = "NC_000004.12", chr5 = "NC_000005.10", chr6= "NC_000006.12", chr7 = "NC_000007.14", chr8= "NC_000008.11", chr9= "NC_000009.12", chr10 = "NC_000010.11", chr11 = "NC_000011.10", chr12 = "NC_000012.12", chr13 = "NC_000013.11", chr14 = "NC_000014.9", chr15 = "NC_000015.10", chr16 = "NC_000016.10", chr17 = "NC_000017.11", chr18 = "NC_000018.10", chr19 = "NC_000019.10", chr20 = "NC_000020.11", chr21 = "NC_000021.9", chr22 = "NC_000022.11", chrX = "NC_000023.11",chrY = "NC_000024.10") 


NoDB_filtered_for_levenscore  <- NoDB_filtered_for_levenscore [NoDB_filtered_for_levenscore $V1 %in% names(chrom_to_accession), ]
NoDB_filtered_for_levenscore  $accession <- chrom_to_accession[match(NoDB_filtered_for_levenscore $V1, names(chrom_to_accession))]

# Define the start and end positions for the reference sequence
NoDB_filtered_for_levenscore  $start <- as.integer(NoDB_filtered_for_levenscore $V2.x) - 1
NoDB_filtered_for_levenscore $end <- NoDB_filtered_for_levenscore  $start + NoDB_filtered_for_levenscore  $alt_length

# Use system() to retrieve the reference sequences
ref_fasta_path <- "/home/briana/shared/AdjacentSequence/ncbi-genomes-2023-04-08/GCF_000001405.40_GRCh38.p14_genomic.fna"
NoDB_filtered_for_levenscore $ref_fasta_cmd_right <- paste0("samtools faidx ", ref_fasta_path, " ", NoDB_filtered_for_levenscore  $accession, ":", NoDB_filtered_for_levenscore  $start+1, "-", NoDB_filtered_for_levenscore  $end)
NoDB_filtered_for_levenscore  $ref_seq_right <- sapply(NoDB_filtered_for_levenscore  $ref_fasta_cmd_right, function(cmd) system(cmd, intern = TRUE)[2])
NoDB_filtered_for_levenscore $ref_fasta_cmd_left <- paste0("samtools faidx ", ref_fasta_path, " ", NoDB_filtered_for_levenscore  $accession, ":", NoDB_filtered_for_levenscore  $start-NoDB_filtered_for_levenscore  $alt_length, "-", NoDB_filtered_for_levenscore  $start-1)
NoDB_filtered_for_levenscore $ref_seq_left <- sapply(NoDB_filtered_for_levenscore  $ref_fasta_cmd_left, function(cmd) system(cmd, intern = TRUE)[2])

# Compare the alt and reference sequences using Levenshtein distance
library(stringdist)
NoDB_filtered_for_levenscore$lev_distance_right <- stringdist(NoDB_filtered_for_levenscore $ref_seq_right, NoDB_filtered_for_levenscore  $V5.x, method = "lv", nthread = 4)
NoDB_filtered_for_levenscore  $lev_distance_left <- stringdist(NoDB_filtered_for_levenscore  $ref_seq_left, NoDB_filtered_for_levenscore  $V5.x, method = "lv", nthread = 4)


# Append the new information as a new column to the variant line
NoDB_filtered_for_levenscore$new_info_right <- ifelse(NoDB_filtered_for_levenscore $lev_distance_right != -1, paste0("Levenshtein=", NoDB_filtered_for_levenscore $lev_distance_right, "| Original sequence(right)=", NoDB_filtered_for_levenscore $ref_seq_right, ", Variant sequence=", NoDB_filtered_for_levenscore $V5), paste0("Levenshtein=", NoDB_filtered_for_levenscore$lev_distance_right, "|"))
NoDB_filtered_for_levenscore $new_info_left <- ifelse(NoDB_filtered_for_levenscore $lev_distance_left != -1, paste0("Levenshtein=", NoDB_filtered_for_levenscore $lev_distance_left, "| Original sequence(left)=", NoDB_filtered_for_levenscore$ref_seq_left, ", Variant sequence=", NoDB_filtered_for_levenscore $V5), paste0("Levenshtein=", NoDB_filtered_for_levenscore $lev_distance_left, "|"))

#This block calculates a ratio of the score over the length of the variant to account for an increased number of of changes in longer #variants, and adds this information to the data frame.

# Add scaled Levenshtein distances to COSV
NoDB_filtered_for_levenscore $lev_distance_right_scaled <- NoDB_filtered_for_levenscore $lev_distance_right / nchar(NoDB_filtered_for_levenscore$V5.x)
NoDB_filtered_for_levenscore $lev_distance_left_scaled <- NoDB_filtered_for_levenscore$lev_distance_left / nchar(NoDB_filtered_for_levenscore$V5.x)



```


```{r}

#Join the DBs back togetherfor no DB entry
library(dplyr)

filtered_result_lines_noDB$lev_distance_right_scaled <- NoDB_filtered_for_levenscore$lev_distance_right_scaled
filtered_result_lines_noDB$lev_distance_left_scaled <- NoDB_filtered_for_levenscore$lev_distance_left_scaled

noDB_filtered_results_final <- filtered_result_lines_noDB %>%
                                 select(V1,V2,V3, genes, VAF, case_reads, controls_total_reads,
                                        lev_distance_right_scaled, lev_distance_left_scaled)


colnames(noDB_filtered_results_final)[1] <- "file_name"
colnames(noDB_filtered_results_final)[2] <- "chromosome"
colnames(noDB_filtered_results_final)[3] <- "chrom_position"
```



```{r}
#Levenshtein score for insertions that meet VAF and control count values for COSV values
#This block determines the Levenshtein score for the data frame for each variant, when comparing the variant to the left and right sequence at the insertion point. 

# Determine the length of the alt sequence
COSV_filtered_for_levenscore $alt_length <- nchar(COSV_filtered_for_levenscore$V5.x)

# Skip variants where the alt sequence is too short (not interested in insertions less than 3 bases)
alt_length_threshold <- 3
COSV_filtered_for_levenscore <- subset(COSV_filtered_for_levenscore , COSV_filtered_for_levenscore $alt_length >= alt_length_threshold)

# Convert the chromosome name to the RefSeq accession number
chrom_to_accession <- list(chr1 = "NC_000001.11", chr2 = "NC_000002.12", chr3 = "NC_000003.12", chr4 = "NC_000004.12", chr5 = "NC_000005.10", chr6= "NC_000006.12", chr7 = "NC_000007.14", chr8= "NC_000008.11", chr9= "NC_000009.12", chr10 = "NC_000010.11", chr11 = "NC_000011.10", chr12 = "NC_000012.12", chr13 = "NC_000013.11", chr14 = "NC_000014.9", chr15 = "NC_000015.10", chr16 = "NC_000016.10", chr17 = "NC_000017.11", chr18 = "NC_000018.10", chr19 = "NC_000019.10", chr20 = "NC_000020.11", chr21 = "NC_000021.9", chr22 = "NC_000022.11", chrX = "NC_000023.11",chrY = "NC_000024.10") 


COSV_filtered_for_levenscore  <- COSV_filtered_for_levenscore [COSV_filtered_for_levenscore $V1 %in% names(chrom_to_accession), ]
COSV_filtered_for_levenscore $accession <- chrom_to_accession[match(COSV_filtered_for_levenscore$V1, names(chrom_to_accession))]

# Define the start and end positions for the reference sequence
COSV_filtered_for_levenscore $start <- as.integer(COSV_filtered_for_levenscore $V2.x) - 1
COSV_filtered_for_levenscore $end <- COSV_filtered_for_levenscore $start + COSV_filtered_for_levenscore $alt_length

# Use system() to retrieve the reference sequences
ref_fasta_path <- "/home/briana/shared/AdjacentSequence/ncbi-genomes-2023-04-08/GCF_000001405.40_GRCh38.p14_genomic.fna"
COSV_filtered_for_levenscore $ref_fasta_cmd_right <- paste0("samtools faidx ", ref_fasta_path, " ", COSV_filtered_for_levenscore $accession, ":", COSV_filtered_for_levenscore $start+1, "-", COSV_filtered_for_levenscore $end)
COSV_filtered_for_levenscore $ref_seq_right <- sapply(COSV_filtered_for_levenscore $ref_fasta_cmd_right, function(cmd) system(cmd, intern = TRUE)[2])
COSV_filtered_for_levenscore $ref_fasta_cmd_left <- paste0("samtools faidx ", ref_fasta_path, " ", COSV_filtered_for_levenscore $accession, ":", COSV_filtered_for_levenscore $start-COSV_filtered_for_levenscore $alt_length, "-", COSV_filtered_for_levenscore $start-1)
COSV_filtered_for_levenscore $ref_seq_left <- sapply(COSV_filtered_for_levenscore $ref_fasta_cmd_left, function(cmd) system(cmd, intern = TRUE)[2])

# Compare the alt and reference sequences using Levenshtein distance
library(stringdist)
COSV_filtered_for_levenscore$lev_distance_right <- stringdist(COSV_filtered_for_levenscore$ref_seq_right, COSV_filtered_for_levenscore $V5.x, method = "lv", nthread = 4)
COSV_filtered_for_levenscore $lev_distance_left <- stringdist(COSV_filtered_for_levenscore $ref_seq_left, COSV_filtered_for_levenscore $V5.x, method = "lv", nthread = 4)


# Append the new information as a new column to the variant line
COSV_filtered_for_levenscore $new_info_right <- ifelse(COSV_filtered_for_levenscore $lev_distance_right != -1, paste0("Levenshtein=", COSV_filtered_for_levenscore $lev_distance_right, "| Original sequence(right)=", COSV_filtered_for_levenscore $ref_seq_right, ", Variant sequence=", COSV_filtered_for_levenscore $V5), paste0("Levenshtein=", COSV_filtered_for_levenscore $lev_distance_right, "|"))
COSV_filtered_for_levenscore $new_info_left <- ifelse(COSV_filtered_for_levenscore $lev_distance_left != -1, paste0("Levenshtein=", COSV_filtered_for_levenscore $lev_distance_left, "| Original sequence(left)=", COSV_filtered_for_levenscore $ref_seq_left, ", Variant sequence=", COSV_filtered_for_levenscore $V5), paste0("Levenshtein=", COSV_filtered_for_levenscore$lev_distance_left, "|"))

#This block calculates a ratio of the score over the length of the variant to account for an increased number of of changes in longer #variants, and adds this information to the data frame.

# Add scaled Levenshtein distances to COSV
COSV_filtered_for_levenscore$lev_distance_right_scaled <- COSV_filtered_for_levenscore$lev_distance_right / nchar(COSV_filtered_for_levenscore$V5.x)
COSV_filtered_for_levenscore$lev_distance_left_scaled <- COSV_filtered_for_levenscore$lev_distance_left / nchar(COSV_filtered_for_levenscore$V5.x)

library(dplyr)

joined_data_COSV <- left_join(filtered_result_lines_COSV, COSV_filtered_for_levenscore, 
                         by = c("V1" = "file_name"))

joined_data_COSV <- select(joined_data_COSV, -c(case_reads.y, controls_total_reads.y, V3.x)) %>%
               rename(case_reads = case_reads.x, controls_total_reads = controls_total_reads.x)



COSV_filtered_results <- select(joined_data_COSV, V1, V2,V6, genes.x, VAF.x, case_reads, 
                         controls_total_reads, lev_distance_right_scaled, 
                         lev_distance_left_scaled)


colnames(COSV_filtered_results)[1] <- "file_name"
colnames(COSV_filtered_results)[2] <- "chromosome"
colnames(COSV_filtered_results)[3] <- "chrom_position"
```



#The following blocks are for data visualisation and table generation


```{r}
#Generate VAF plot for genes in COSMIC census 
# Load the ggplot2 package
library(ggplot2)

COSV_genes_only_df$V2 <- factor(COSV_genes_only_df$V2)

# Create the facet-wrapped box plots
VAFforCOSMICCensus <- ggplot(COSV_genes_only_df, aes(x = V2, y = VAF)) +  # swapped x and y
  geom_boxplot() +
  labs(x = "Genes", y = "VAF") +  # updated x and y labels
  ggtitle("Estimated VAF scores for TCGA TARGET AML cohort genes found in the COSMIC cancer census database ") +
  theme_bw() +
  theme(axis.text.y = element_text(angle = 0, hjust = 1, size = 20), plot.title = element_text(size = 30), axis.text.x = element_text(size = 20), axis.title.x = element_text(size = 30), axis.title.y = element_text(size = 30))

# Save plot to file
filepath <- "/home/briana/shared/VAFDistribution.png"
ggsave(filepath, width = 20, height = 10, dpi = 300)

```


```{r}
#Generate VAF plot for genes not in COSMIC census 
# Load the ggplot2 package
library(ggplot2)

filtered_VAF_noCOSMIC_values$V2 <- factor(filtered_VAF_noCOSMIC_values$V2)

# Create the facet-wrapped box plots
VAFfornoCOSMICCensus <- ggplot(filtered_VAF_noCOSMIC_values, aes(x = V2, y = VAF)) +  # swapped x and y
  geom_boxplot() +
  labs(x = "Genes", y = "VAF") +  # updated x and y labels
  ggtitle("Estimated VAF scores for TCGA TARGET AML cohort genes with no associated database entry") +
  theme_bw() +
  theme(axis.text.y = element_text(angle = 0, hjust = 1, size = 20), plot.title = element_text(size = 30), axis.text.x = element_text(size = 20), axis.title.x = element_text(size = 30), axis.title.y = element_text(size = 30))

# Save plot to file
filepath <- "/home/briana/shared/noCOSVAFDistribution.png"
ggsave(filepath, width = 20, height = 10, dpi = 300)

```

```{r}
#Bar plot for high and moderate genes with no associated database entry 
library(ggplot2)

# Subset data to include only variants with no DB entry
df_split_noDBENTRY <- subset(df_split, (`ExistingVariant` == "") & (`col3` == "HIGH" | `col3` == "MODERATE"))

# Aggregate data by gene and variant and count the number of occurrences
gene_counts <- aggregate(`ExistingVariant` ~ col4, data = df_split_noDBENTRY, FUN = function(x) length(x))

# Order the genes by count of variants
gene_counts_sorted <- gene_counts[order(gene_counts$`ExistingVariant`, decreasing = TRUE), ]

# Keep only the top 20 col4 values
top_20_gene_counts <- head(gene_counts_sorted, 20)


# Create bar plot
highmodnodb <- ggplot(top_20_gene_counts, aes(x = reorder(col4, `ExistingVariant`), y = `ExistingVariant`, fill = `ExistingVariant`)) +
  geom_bar(stat = "identity") +
  labs(fill = "Consequence\n by Count",x = "Gene", y = "HIGH and MODERATE Consequence count") +  theme_light() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size =20),axis.title.x = element_text(size = 20),
        plot.title = element_text(hjust = 0.5, size = 20)) + 
  ggtitle("VEP determined HIGH or MODERATE consequence MINTIE insertions with\n no associated database entry in TCGA TARGET AML cohort")

filepath <- "/home/briana/shared/HIGHMODnoDBENTRY.png" 
png(filepath, width = 1300, height = 1100)
plot(highmodnodb)
dev.off()


```



```{r HIGH or MODERATE con}

#Bar plot for genes with high mod in COSMIC

library(ggplot2)

# Subset data to include only variants that start with "COS"
combined_df_sub <- subset(combined_df, grepl("^COS", `Existing Variant`) & (`Consequence` == "HIGH" | `Consequence` == "MODERATE"))

# Aggregate data by gene and variant and count the number of occurrences
gene_counts <- aggregate(`Existing Variant` ~ Gene, data = combined_df_sub, FUN = function(x) length(x))

# Order the genes by count of variants
gene_counts_sorted <- gene_counts[order(gene_counts$`Existing Variant`, decreasing = TRUE), ]

# Create bar plot
highmodcos <- ggplot(gene_counts_sorted, aes(x = reorder(Gene, `Existing Variant`), y = `Existing Variant`, fill = `Existing Variant`)) +
  geom_bar(stat = "identity") +
  labs(fill = "Consequence\n by Count",x = "Gene", y = "HIGH and MODERATE Consequence count") +  theme_light() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size =20),axis.title.x = element_text(size = 20),
        plot.title = element_text(hjust = 0.5, size = 20)) + 
  ggtitle("VEP determined HIGH or MODERATE consequence MINTIE insertions with\n associated COSMIC entry in TCGA TARGET AML cohort")

filepath <- "/Users/Briana/Desktop/Uni/Briana Project Stuff/getVEPRunning/ProcessedVEPInsertions/FilesforRProcessing/ProcessingVEPOutput/Graphics/HIGHMODCOS.png" 
png(filepath, width = 1300, height = 1100)
plot(highmodcos)
dev.off()




```

```{r}
library(ggplot2) 
library(ggthemes)

# Subset rows where consequence is HIGH or MODERATE
df_subset <- subset(combined_df, Consequence %in% c("HIGH", "MODERATE"))

# Aggregate data by gene and consequence and count the number of occurrences
gene_counts <- aggregate(Consequence ~ Gene, data = df_subset, FUN = function(x) length(x))

# Order the genes by count of consequences and select top 20
top_20_genes <- gene_counts[order(gene_counts$Consequence, decreasing = TRUE), ][1:50,]

# Create bar plot
topfifty <- ggplot(top_20_genes, aes(x = reorder(Gene, Consequence), y = Consequence, fill = Consequence)) +
  geom_bar(stat = "identity") +
  labs(fill = "Consequence\n by Count",x = "Gene", y = "HIGH and MODERATE Consequence Combined Count ", title = "VEP determined top 50 genes by count associated with MODERATE and HIGH consequence MINTIE insertions\n in TCGA TARGET AML cohort", ) +
  theme_light() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 20),  plot.title = element_text(hjust = 0.5, size =40), axis.text.y = element_text(size = 20), axis.title.y = element_text(size=20), axis.title.x = element_text(size = 30))

filepath <- "/Users/Briana/Desktop/Uni/Briana Project Stuff/getVEPRunning/ProcessedVEPInsertions/FilesforRProcessing/ProcessingVEPOutput/Graphics/HIGHMODCOStop50.png"   
png(filepath, width = 2000, height = 1800)
plot(topfifty)
dev.off()


```



```{r Insertion length distribution}
library(ggplot2) 
library(ggthemes)

distribution_plot <- ggplot(df_split, aes(x = SVLEN)) +
  geom_histogram(alpha = 0.5, fill = "lightgreen", color = "darkgreen", binwidth = .02, bins = 50) +
  labs(y = "Count (log10)", x = "Insertion length (bp (log10)) ",title = "Length distribution of VEP determined High and Moderate MINTIE insertions in TCGA TARGET AML Cohort") +
  theme_light() +
  scale_x_log10(limits = c(10, 1000)) +
  guides(x = guide_axis(angle = 90))

modifieddistplot <- distribution_plot + 
  theme(plot.title = element_text(size = 20,hjust = 0.5), 
        axis.title.x = element_text(size = 15),
        axis.text.x = element_text(size = 12),
        axis.text.y = element_text(size=12),
        axis.title.y = element_text(size = 15), 
        legend.position = "bottom"
        )


filepath <- "/home/briana/shared/InsertionLengthDistribution_TCGA_TARGET_AML.png" 
png(filepath, width = 1300, height = 1100)
plot(modifieddistplot)
dev.off()


```


```{r}
#COSMIC Insertion length distribution

library(ggplot2) 
library(ggthemes)

distribution_plot <- ggplot(df_filtered_COS, aes(x = SVLEN)) +
  geom_histogram(alpha = 0.5, fill = "lightgreen", color = "darkgreen", binwidth = .05, bins = 10) +
  labs(y = "Count (log10)", x = "Insertion length (bp (log10)) ",title = "Length distribution of COSMIC associated MINTIE insertions in TCGA TARGET AML Cohort") +
  theme_light() +
  scale_x_log10(limits = c(10, 1000)) +
  guides(x = guide_axis(angle = 90))

modifieddistplot <- distribution_plot + 
  theme(plot.title = element_text(size = 20,hjust = 0.5), 
        axis.title.x = element_text(size = 15),
        axis.text.x = element_text(size = 12),
        axis.text.y = element_text(size=12),
        axis.title.y = element_text(size = 15), 
        legend.position = "bottom"
        )


filepath <- "/home/briana/shared/COSMIC_InsertionLengthDistribution_TCGA_TARGET_AML_HIGH_MOD_NO_RS.png" 
png(filepath, width = 1300, height = 1100)
plot(modifieddistplot)
dev.off()
```


```{r fig.height = 10, fig.width = 5}

library(dplyr)

genes <- df_split %>% 
  filter(Consequence %in% c("MODERATE", "HIGH")) %>% 
  group_by(Gene) %>% 
  summarize(count = n()) %>% 
  arrange(desc(count)) %>% 
  head(26) %>% 
  pull(Gene)


gene_df <- data.frame(genes)
write.csv(gene_df,"/Users/Briana/Desktop/Uni/Briana Project Stuff/getVEPRunning/ProcessedDeletions/TopGenes.png/Users/Briana/Desktop/Uni/Briana Project Stuff/getVEPRunning/ProcessedDeletions/DeletionLengthDistribution.png", row.names = FALSE)



```

```{r}
library(dplyr)

# Filter for genes with COSV entries and moderate/high consequences
genes <- df_split %>%
  filter(grepl("COSV", `Existing Variant`) & Consequence %in% c("MODERATE", "HIGH")) %>%
  group_by(Gene, `Existing Variant`) %>%
  summarize(count = n()) %>%
  ungroup()

# Write the list of genes to a CSV file
write.csv(genes, "/Users/Briana/Desktop/Uni/Briana Project Stuff/getVEPRunning/ProcessedDeletions/cosmic.csv", row.names = FALSE)



```

```{r fig.height = 60, fig.width = 30}
library(ggplot2)

# Subset the data to include HIGH, MODERATE, and LOW consequence variants
df_filtered <- df_split[df_split$Consequence %in% c("HIGH", "MODERATE"),]

# Aggregate the data by GenomicImpact
agg_data <- aggregate(file_name ~ GenomicImpact, data = df_filtered, FUN = length)

# Create the bar chart
genomicimpactnomodifier <- ggplot(agg_data, aes(x = GenomicImpact, y = file_name, fill = GenomicImpact)) + theme_light() +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "HIGH and MODERATE MINTIE deletion\n genomic impact distribution in TCGA TARGET AML",
       x = "Genomic Impact",
       y = "Count") + 
  theme(plot.title = element_text(hjust = 0.5, size = 20),
        axis.text.x = element_text(angle = 45, hjust = 1, size =15),
        axis.title.x =element_text(size =20),
        axis.title.y = element_text(size = 20),
        axis.text = element_text(size = 15),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 14))




filepath <- "/Users/Briana/Desktop/Uni/Briana Project Stuff/getVEPRunning/ProcessedDeletions/GenomicImpactNoModifier.png" 
png(filepath, width = 1300, height = 1100)
plot(genomicimpactnomodifier)
dev.off()





```

```{r fig.height = 50, fig.width = 25}
# Create a new column to store the updated existing variant entries
df_split$UpdatedExistingVariant <- ""

# Loop through each row in the df_split data frame
for(i in 1:nrow(df_split)) {
  
  # Check if the existing variant contains "COSV" or "RS" or both
  has_cosv <- grepl("COSV", df_split[i, "Existing Variant"])
  has_rs <- grepl("rs", df_split[i, "Existing Variant"])
  
  # Assign a value to the UpdatedExistingVariant column based on the presence of "COSV" and "RS"
  if(has_cosv & has_rs) {
    df_split[i, "UpdatedExistingVariant"] <- "COS&rs"
  } else if(has_cosv) {
    df_split[i, "UpdatedExistingVariant"] <- "COSV"
  } else if(has_rs) {
    df_split[i, "UpdatedExistingVariant"] <- "rs"
  } else if(df_split[i, "Existing Variant"] == "N/A") {
    df_split[i, "UpdatedExistingVariant"] <- "NONE"
  } else {
    df_split[i, "UpdatedExistingVariant"] <- "Other"
  }
}

# Create a new data frame with the ExistingVariant, UpdatedExistingVariant, and Consequence columns
df_existing <- df_split[, c("Existing Variant", "UpdatedExistingVariant", "Consequence", "GenomicImpact")]



```


```{r fig.height = 1000, fig.width = 500}
library(ggplot2)

df_existing <- df_existing[df_existing$Consequence != "MODIFIER",]

library(ggplot2)

# Count the number of variants for each value in the UpdatedExistingVariant column
agg_data <- aggregate(df_existing$Consequence, 
                      by = list(df_existing$UpdatedExistingVariant, df_existing$GenomicImpact), 
                      FUN = length)
names(agg_data) <- c("UpdatedExistingVariant", "GenomicImpact", "Count")

# Create the bar chart
databaseentries <- ggplot(agg_data, aes(x = UpdatedExistingVariant, y = Count, fill = GenomicImpact)) +
  geom_bar(stat = "identity") +
   theme_light() +
  labs(title = "VEP MODERATE and HIGH Consequence MINTIE deletions by associated database\n in TCGA TARGET AML",
       x = "Database ",
       y = "Count", fill="Genomic impact") +
  theme(plot.title = element_text(hjust = 0.5, size = 35),
        axis.text.x = element_text(angle = 45, hjust = 1, size =25),
        axis.title.x =element_text(size =20),
        axis.title.y = element_text(size = 20),
        axis.text = element_text(size = 25),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 14),
        legend.position = "bottom", # Move the legend to the bottom
        legend.box = "horizontal")  # Display the legend horizontally)

filepath <- "/Users/Briana/Desktop/Uni/Briana Project Stuff/getVEPRunning/ProcessedDeletions/HIMODINSbyDB.png" 
png(filepath, width = 4000, height = 3800)
plot(databaseentries)
dev.off()


```


```{r fig.height = 250, fig.width = 175}


# Aggregate the data by GenomicImpact
agg_data <- aggregate(file_name ~ Consequence, data = df_split, FUN = length)

# Create the bar chart
genomicimpactnomodifier <- ggplot(agg_data, aes(x = Consequence, y = file_name)) + theme_light() +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "Consequence distribution for MINTIE insertions in TCGA TARGET AML cohort",
       x = "VEP determined Genomic Impact",
       y = "Count") + 
  theme(plot.title = element_text(hjust = 0.5, size = 30),
        axis.text.x = element_text(angle = 45, hjust = 1, size =15),
        axis.title.x =element_text(size =20),
        axis.title.y = element_text(size = 20),
        axis.text = element_text(size = 15),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 14))




filepath <- "/Users/Briana/Desktop/Uni/Briana Project Stuff/getVEPRunning/ProcessedVEPInsertions/FilesforRprocessing/ProcessingVEPOutput/ConsequenceDistribution.png"  
png(filepath, width = 1300, height = 1100)
plot(genomicimpactnomodifier)
dev.off()








```


```{r }
library(ggplot2)

# Filter out the rows where Consequence is "MODIFIER"
df_filtered <- df_split[df_split$Consequence != "MODIFIER",]

# Create the violin plot
violin_plot <- ggplot(df_split, aes(x = Gene, y = SVLEN)) +
  geom_violin(trim = FALSE) +
  scale_y_continuous(name = "SVLEN") +
  labs(title = "Distribution of deletion length by Gene") +
  theme(plot.title = element_text(hjust = 0.5, size = 20))

# Facet the violin plot by Gene
violin_plot_faceted <- violin_plot + facet_wrap(~ Gene, scales = "free")


filepath <- "/Users/Briana/Desktop/Uni/Briana Project Stuff/getVEPRunning/ProcessedDeletions/consequencedistribution.png" 
png(filepath, width = 20000, height = 10000)
plot(violin_plot_faceted)
dev.off()


```

```{r }
library(ggplot2)

# Create bar graph with counts
consequence_plot <- ggplot(data = df_split, aes(x = Consequence, y = ..count..)) + theme_light() +
  geom_bar(fill = "darkgrey") +
  labs(title = "Consequence distribution for MINTIE insertions in TCGA TARGET AML cohort", x = "VEP determined consequence", y = "Count") +
  theme(plot.title = element_text(hjust = 0.5, size = 20))


filepath <- "/Users/Briana/Desktop/Uni/Briana Project Stuff/getVEPRunning/ProcessedVEPInsertions/FilesforRProcessing/ProcessingVEPOutput/Graphics/Insertion_Consequence_Distribution.png" 
png(filepath, width = 1000, height = 800)
plot(consequence_plot )
dev.off()
```


```{r}

# filter rows based on conditions and create new dataframe
low_lev_score_df <- df_split[(df_split$lev_distance_right_scaled < 0.2 | 
                            df_split$lev_distance_left_scaled < 0.2) & 
                            (df_split$ExistingVariant == "") &
                            (df_split$col3 %in% c("MODERATE", "HIGH")) & 
                            (df_split$col3 != "MODIFIER"),]


library(ggplot2)

# count the number of occurrences for each gene and score type
gene_counts <- low_lev_score_df %>%
  group_by(col4) %>%
  summarise(right_score_count = sum(lev_distance_right_scaled < 0.2),
            left_score_count = sum(lev_distance_left_scaled < 0.2))

# sort genes by right_score_count and select top 10
top_genes_right <- gene_counts[order(gene_counts$right_score_count, decreasing = TRUE),][1:10,]
# sort genes by left_score_count and select top 10
top_genes_left <- gene_counts[order(gene_counts$left_score_count, decreasing = TRUE),][1:10,]

# create a bar graph of top genes by right_score_count
lev_right_plot <- ggplot(top_genes_right, aes(x = reorder(col4, -right_score_count), y = right_score_count)) +
  geom_bar(stat = "identity") +
  ggtitle("Top Genes by Levenshtein Distance Right Score Count (<= 0.2)") +
  xlab("Gene") +
  ylab("Count")



# create a bar graph of top genes by left_score_count
 lev_plot_left <- ggplot(top_genes_left, aes(x = reorder(col4, -left_score_count), y = left_score_count)) +
  geom_bar(stat = "identity") +
  ggtitle("Top Genes by Levenshtein Distance Left Score Count (<= 0.2)") +
  xlab("Gene") +
  ylab("Count")






```



```{r}
library(ggplot2)

# Filter the data frame to include only rows where ExistingVariant is blank and where the scaled Levenshtein distance scores are 0, and exclude modifier values in col3
filtered_df <- subset(df_split, ExistingVariant == "" & (lev_distance_left_scaled == 0 | lev_distance_right_scaled == 0) & !(col3 %in% c("MODIFIER")))

# Convert fill variable to a factor and set labels
filtered_df$fill_factor <- factor(ifelse(filtered_df$lev_distance_left_scaled == 0, "Left Scaled Score", "Right Scaled Score"), 
                                  levels = c("Left Scaled Score", "Right Scaled Score"))

genevariantplot <- ggplot(filtered_df, aes(x = col34, y = ..count.., fill = fill_factor)) +
  geom_bar(position = position_dodge(width = 0.9), stat = "count") +
  ggtitle("Genes containing Variants with Scaled Levenshtein Distance Scores of 0") +
  xlab("Gene Name") +
  ylab("Number of Variants") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_fill_manual(values = c("#0072B2", "#E69F00"), labels = c("Left Scaled Score", "Right Scaled Score"))

# Increase spacing between bars
genevariantplot = genevariantplot + theme(panel.spacing.x = unit(5, "cm"))



# Save plot to file
filepath <- "/home/briana/shared/AdjacentSequence/Geneswithduplicatedinsertions"
png(filepath, width = 3000, height = 800)
plot(genevariantplot)
dev.off()



```

```{r}
library(dplyr)

# Filter the data frame to include only rows where ExistingVariant is blank and where the scaled Levenshtein distance scores are 0, and exclude modifier values in col3
filtered_df <- subset(df_split, ExistingVariant == "" & (lev_distance_left_scaled <= .4 | lev_distance_right_scaled <= .4) & !(col3 %in% c("MODIFIER")))

# Select only the genes with 50 or more Levenshtein scores of 0
gene_counts <- filtered_df %>%
  group_by(col34) %>%
  summarise(num_variants = n()) %>%
  filter(num_variants >= 50)

# Join with the filtered_df to get the lines used to make the plot
table_df_lev <- filtered_df %>%
  filter(col34 %in% gene_counts$col34) %>%
  select(file_name, col4, lev_distance_left_scaled, new_info_left, lev_distance_right_scaled, new_info_right)

# View the resulting table
table_df_lev

write.csv(table_df, file = "/home/briana/shared/AdjacentSequence/adjacentnoveltable.csv", row.names = FALSE, )
```

```{r}
library(dplyr)

# Filter the data frame to include only rows where ExistingVariant is blank and where the scaled Levenshtein distance scores are 0, and exclude modifier values in col3
filtered_df <- subset(df_split, ExistingVariant != "" & (lev_distance_left_scaled <= .4 | lev_distance_right_scaled <= .4) & !(col3 %in% c("MODIFIER")))

# Select only the genes with 5 or more Levenshtein scores of 0 or less than or equal to 0.4
gene_counts <- filtered_df %>%
  group_by(col34) %>%
  summarise(num_variants = sum(lev_distance_left_scaled <= 1 | lev_distance_right_scaled <= 1)) %>%
  filter(num_variants >= 5)


# Join with the filtered_df to get the lines used to make the plot
table_df <- filtered_df %>%
  filter(col34 %in% gene_counts$col34) %>%
  select(file_name,col4,ExistingVariant,col3,V5,V1,V2, lev_distance_left_scaled, new_info_left, lev_distance_right_scaled, new_info_right)

# View the resulting table
table_df

write.csv(table_df, file = "/home/briana/shared/AdjacentSequence/adjacentexistingtable.csv", row.names = FALSE, )
```


```{r}

#This block creates a stacked bar plot showing the genomic impact and insertion count 
library(ggplot2) 
library(ggthemes)

# Subset rows where consequence is HIGH or MODERATE
df_subset <- subset(combined_df, col3 %in% c("HIGH", "MODERATE"))

# Aggregate data by gene, consequence, and col2 and count the number of occurrences
gene_counts <- aggregate(col3 ~ col4 + col2, data = df_subset, FUN = function(x) length(x))
top_50_genes <- gene_counts[order(gene_counts$col3, decreasing = TRUE), ][1:100, ]


# Create bar plot
topfifty <- ggplot(top_50_genes, aes(x = reorder(col4, col3), y = col3, fill = col2)) +
  geom_bar(stat = "identity") +
  labs(fill = "Genomic Consequence\n by Count",x = "Gene", y = "HIGH and MODERATE Consequence Combined Count ", title = "VEP determined top 100 genes by count associated with MODERATE and HIGH consequence MINTIE insertions\n in TCGA TARGET AML cohort", ) +
  theme_light() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 20), plot.title = element_text(hjust = 0.5, size = 40), axis.text.y = element_text(size = 20), axis.title.y = element_text(size = 20), axis.title.x = element_text(size = 30),
        legend.text = element_text(size = 30), legend.title = element_text(size=35)) # Set font size of legend labels

filepath <- "/home/briana/shared/HIGHMODCOStop50.png"   
png(filepath, width = 3000, height = 2800)

plot(topfifty)
dev.off()




```

```{r}
#Export matching_Id_df 

sample_name <- matching_Id_df[, 1]

write.table(sample_name, "/home/briana/shared/matchingdata.txt", sep = "\t", row.names = FALSE)


```

```{r}
#Save results of interest to PDF


library(gridExtra)
library(grid)

#Generate PDF with summerized information 

#Generate highest histology count from results_df_summary_split

# Find the highest count Primary_histology and Histology_subtype
max_primary_histology <- results_df_gene_summary$Primary_histology[which.max(results_df_gene_summary$Count)]
max_subtype <- results_df_gene_summary$Histology_subtype[which.max(results_df_gene_summary$Count)]

# Create the PDF and add the title
pdf("/home/briana/shared/test_two.pdf", height=20, width=38)
grid.text(paste("The highest histology by COSV id count is: ", max_primary_histology, " and the highest histology subtype by unique COSV id count is: ", max_subtype, ".\n All COSV identifiers included here are linked to mutations in genes listed in the Cancer Gene Census (http://cancer.sanger.ac.uk/census)\n 'The Cancer Gene Census (CGC) is an ongoing effort to catalogue those genes which contain mutations that have been causally implicated in cancer and explain how dysfunction of these genes drives cancer.\n The content, the structure, and the curation process of the Cancer Gene Census was described and published in Nature Reviews Cancer'"), x=0.5, y=0.95, gp=gpar(fontsize=20))
grid.table(results_df_gene_summary)

# Define the number of rows per page
rows_per_page <- 30

# Get the total number of rows in the data frame
total_rows <- nrow(matching_Id_df)

# Calculate the number of pages required to display all rows
num_pages <- ceiling(total_rows / rows_per_page)

# Loop through each page
for (i in 1:num_pages) {
  # Subset the data frame to the appropriate rows for this page
  start_row <- (i - 1) * rows_per_page + 1
  end_row <- min(start_row + rows_per_page - 1, total_rows)
  page_df <- matching_Id_df[start_row:end_row, ]
  
  # Create a table grob for the page
  table_grob <- tableGrob(page_df)
  
  # Draw the table on a new PDF page
  grid.newpage()
  grid.text(paste("Samples linked to genes in the Cancer Census database. Page ", i), x=0.5, y=0.95, gp=gpar(fontsize=20))
  grid.draw(table_grob)
}


grid.newpage()
grid.draw(topfifty)

grid.newpage()

grid.arrange(
  lev_right_plot , lev_plot_left , ncol = 2,
  widths = c(1, 1), heights = c(1, 1)
)
grid.text(paste("A first approach at detecting ITD/duplications. ScanITD (2020) used a simple string comparsion algorithm to detect ITDs. My approach might be wrong so have not checked too closely.\n Top HIGH and MODERATE variants with no DB entry by Levenshtein ratio count. The left and right sequence of the point of insertion was taken then a Levenshtein score generated.\n This was then divided by the length of the variant to account for longer variants having greater changes (as opposed to a single score cut-off).\n Lower ratio scores mean greater similarity between the variant and the sequence it's adjacent to."),x=0.5, y=.3, gp=gpar(fontsize=30))

grid.newpage()
grid.draw(VAFforCOSMICCensus)



# Close the PDF file
dev.off()





```

```{r}
library(gridExtra)
library(grid)

#Generate PDF with summarized information for new information

#Generate highest histology count from results_df_summary_split

# Create the PDF and add the title
pdf("/home/briana/shared/exploratory_insertions.pdf", height=20, width=38)

grid.text(paste("Result of filtering on insertion variants with associated COSV entry. Selected variants had >100 case_reads and >25 controls_total_reads. \n ****I used the Levenshtein score because I couldn't find any ITD detectors that would be straight forward in R - for example, some required out-put from other variant callers, I might need to have a closer look, happy to discuss ideas at meeting though***"), x=0.5, y=0.95, gp=gpar(fontsize=20))
grid.table(COSV_filtered_results)

# Define the number of rows per page
rows_per_page <- 30

# Get the total number of rows in the data frame
total_rows <- nrow(noDB_filtered_results_final)

# Calculate the number of pages required to display all rows
num_pages <- ceiling(total_rows / rows_per_page)

# Loop through each page
for (i in 1:num_pages) {
  # Subset the data frame to the appropriate rows for this page
  start_row <- (i - 1) * rows_per_page + 1
  end_row <- min(start_row + rows_per_page - 1, total_rows)
  page_df <- noDB_filtered_results_final[start_row:end_row, ]
  
  # Create a table grob for the page
  table_grob <- tableGrob(page_df)
  
  # Draw the table on a new PDF page
  grid.newpage()
  grid.text(paste("With the same filtering applied to the COSV linked variants, there are around 800 non-database linked high and moderate variants. With stricter filtering >1000 case reads and >500 controls_total_reads and VAF >0.1 get 83.\n***Not 100% sure if I used the correct things to filter off the result file, but I can easily change the thresholds and include any other filtering based on the result file*** Page: ", i), x=0.5, y=0.95, gp=gpar(fontsize=20))
  grid.draw(table_grob)
}



```


```{r}
library(dbplyr)

#Get numbers of rows 

totalINS <- nrow(df_split)

mask <- !grepl("(regulatory_region|TF_binding_site|intergenic_variant|upstream_gene_variant|5_prime_UTR_variant|start_retained_variant|start_lost|splice_donor_variant|splice_acceptor_variant|splice_region_variant|splice_donar_variant_5th_base_variant|splice_donor_region _variant|splice_polypyrimidine_tract_variant|intron_variant|3_prime_UTR_variant|downstream_gene_variant).*", df_split$col2)

df_filtered_INSCODING <- df_split[mask, ]

n_rows_coding_regions_INS <- nrow(df_filtered_INSCODING)

# create a boolean mask
mask <- !(grepl("(regulatory region|TF binding site|intergenic variant|upstream gene variant|5 prime UTR variant|start retained variant|start lost|splice donor variant|splice acceptor variant|splice region variant|splice donar variant 5th base variant|splice donor region variant|splice polypyrimidine tract variant|intron variant|3 prime UTR variant|downstream gene variant).*", df_split$col2) | df_split$col3 == "LOW" | df_split$col3 == "MODIFIER")

# filter the dataframe
df_filtered_HIGH_MOD <- df_filtered_INSCODING[mask, ]

# count the number of rows
n_rows_coding_regions_INS_HIGH_MOD <- nrow(df_filtered_HIGH_MOD)

mask <- !(grepl("(regulatory region|TF binding site|intergenic variant|upstream gene variant|5 prime UTR variant|start retained variant|start lost|splice donor variant|splice acceptor variant|splice region variant|splice donar variant 5th base variant|splice donor region variant|splice polypyrimidine tract variant|intron variant|3 prime UTR variant|downstream gene variant).*", df_split$col2) | df_split$col3 == "LOW" | df_split$col3 == "MODIFIER" | !grepl("COSV", df_split$col18) | !grepl("rs", df_split$col18))


# filter the dataframe
df_filtered_COS_DBSNP <- df_split[mask, ]

# count the number of rows
n_rows_COSV_DBSNP_HIGH_MOD <- nrow(df_filtered)

mask <- !(grepl("(regulatory region|TF binding site|intergenic variant|upstream gene variant|5 prime UTR variant|start retained variant|start lost|splice donor variant|splice acceptor variant|splice region variant|splice donar variant 5th base variant|splice donor region variant|splice polypyrimidine tract variant|intron variant|3 prime UTR variant|downstream gene variant).*", df_split$col2) | df_split$col3 == "LOW" | df_split$col3 == "MODIFIER" | grepl("COSV", df_split$col18) | !grepl("rs", df_split$col18))


# filter the dataframe
df_filtered_noCOS <- df_split[mask, ]

# count the number of rows
n_rows_NOCOSV_DBSNP_HIGH_MOD <- nrow(df_filtered_noCOS)

df_filtered_COS <- subset(df_split, col3 != "LOW" & col3 != "MODIFIER" & grepl("COSV", col18) & !grepl("rs", col18))

# count the number of rows
n_rows_COSV_NODBSNP_HIGH_MOD <- nrow(df_filtered_COS )


mask <- grepl("COSV",df_split$col18)

# filter the dataframe
df_filtered_ALL_COS <- df_split[mask, ]

# count the number of rows
n_rows_ALL_COS <- nrow(df_filtered_ALL_COS)



```


```{r}

#COSMIC Insertion length distribution

library(ggplot2) 
library(ggthemes)

distribution_plot <- ggplot(df_filtered_COS, aes(x = SVLEN)) +
  geom_histogram(alpha = 0.5, fill = "lightgreen", color = "darkgreen", binwidth = .2, bins = 5) +
  labs(y = "Count (log10)", x = "Insertion length (bp (log10)) ",title = "Length distribution of 'HIGH' and 'MODERATE' impact COSMIC associated MINTIE insertions in TCGA TARGET AML Cohort") +
  theme_light() +
  scale_x_log10(limits = c(10, 1000)) +
  guides(x = guide_axis(angle = 90))

modifieddistplot <- distribution_plot + 
  theme(plot.title = element_text(size = 20,hjust = 0.5), 
        axis.title.x = element_text(size = 15),
        axis.text.x = element_text(size = 12),
        axis.text.y = element_text(size=12),
        axis.title.y = element_text(size = 15), 
        legend.position = "bottom"
        )


filepath <- "/home/briana/shared/COSMIC_InsertionLengthDistribution_TCGA_TARGET_AML_HIGH_MOD_NO_RS.png" 
png(filepath, width = 1300, height = 1100)
plot(modifieddistplot)
dev.off()
```
```{r}


#COSMIC Insertion length distribution

library(ggplot2) 
library(ggthemes)

distribution_plot <- ggplot(df_filtered_ALL_COS, aes(x = SVLEN)) +
  geom_histogram(alpha = 0.5, fill = "lightgreen", color = "darkgreen", binwidth = .07, bins = 15) +
  labs(y = "Count (log10)", x = "Insertion length (bp (log10)) ",title = "Length distribution of COSMIC associated MINTIE insertions in TCGA TARGET AML Cohort") +
  theme_light() +
  scale_x_log10(limits = c(10, 1000)) +
  guides(x = guide_axis(angle = 90))

modifieddistplot <- distribution_plot + 
  theme(plot.title = element_text(size = 20,hjust = 0.5), 
        axis.title.x = element_text(size = 15),
        axis.text.x = element_text(size = 12),
        axis.text.y = element_text(size=12),
        axis.title.y = element_text(size = 15), 
        legend.position = "bottom"
        )


filepath <- "/home/briana/shared/COSMIC_InsertionLengthDistribution_TCGA_TARGET_AML_ALL.png" 
png(filepath, width = 1300, height = 1100)
plot(modifieddistplot)
dev.off()
```


